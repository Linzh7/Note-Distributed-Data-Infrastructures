Hadoop is a distributed framework developed by Apache, and the core of Hadoop is the storage, namely, the Hadoop Distributed File System (HDFS).

HDFS and other distributed file systems use the same strategies to organize storage space. They mark the manager computers as *NameNode* and the storage computers as *DataNode*. All transmissions among computers are TCP, which could reduce the transmission error rate. The metadata stored at NameNode are the records of permission, date, namespace, etc., which are maintained in memory to increase the access speed. Also, these metadata have backups and logs to improve fault tolerance. Additionally, NameNodes could also play another role in HDFS: *CheckpointNode* or *BackupNode*. CheckpointNode usually downloads the recent checkpoint and logs, then combines them to get a new checkpoint and returns it to NameNode. BackupNode is more like a shadow of NameNode, it will not only create checkpoints but also maintain a real-time image of NameNode. Both are designed to improve the fault tolerance of NameNode.

The biggest difference between HDFS and other systems is that HDFS copies the same data to several DataNodes instead of protecting it with RAID. That is a trade-off between data availability and available storage space. This strategy enables users to access data from the closest DataNode without any unnecessary transmission, which means it saves lots of bandwidth, one of the most important resources in the data warehouse. HDFS stores data in three different DataNodes by default. It is also worth mentioning that the location of three DataNodes. The first DataNodes and second one are located at the same rack, while the third DataNode is located at a different rack. This strategy is aimed to improving write performance and saving bandwidth without harming fault tolerance. Specifically, if one rack faces some problems, there are still other copies available. The two copies on the same rack could reduce the traffic between racks, because they only use ToR switch. Moreover, these policies also allow the NameNode distribute tasks to the nearest DataNode, which reduces the latency of computing. Additionally, there is a report that claims that most operations will have good performance when the free disk space is greater than 40%. Therefore, HDFS also maintains the load balance among DataNodes.

![[Pasted image 20221108175156.png]]

%%Another important policy is the communication between NameNodes and DataNodes. Aside from the regular storage report from DataNodes, they also use heartbeats to make sure that DataNodes are still accessible. Moreover, NameNodes will not communicate directly with DataNodes, instead, NameNodes send information by replying heartbeats.%%

According to Brewerâ€™s CAP theorem, the I/O operation is usually the trickiest part in distributed systems, as those systems should always maintain partition tolerance. The result of the tread-off is that HDFS gives up a certain level of availability because the authors acknowledge that programmer cannot be certain of the time to process an operation. Conversely, we can see that did well in consistency and partition tolerance by lease and verifying data with NameNodes. From this point, HDFS can handle 



