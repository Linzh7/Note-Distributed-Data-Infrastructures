Hadoop is a distributed framework developed by Apache, and the core of Hadoop is the storage, namely, the Hadoop Distributed File System (HDFS).

HDFS and other distributed file systems use the same strategies to organize storage space. They mark the manager computers as *NameNode* and the storage computers as *DataNode*. The metadata stored at NameNode are the records of permission, date, namespace, etc., which are maintained in memory to increase the access speed. Also, these metadata have backups and logs to improve fault tolerance. Additionally, NameNodes could also play another role in HDFS: *CheckpointNode* or *BackupNode*. CheckpointNode usually downloads the recent checkpoint and logs, then combines them to get a new checkpoint and returns it to NameNode. BackupNode is more like a shadow of NameNode, it will not only create checkpoints but also maintain a real-time image of NameNode. Both are designed to improve the fault tolerance of NameNode.

The biggest difference between HDFS and other systems is that HDFS copies the same data to several DataNodes instead of protecting it with RAID. That is a trade-off between data availability and available storage space. This strategy enables users to access data from the closest DataNode without any unnecessary transmission, which means it saves lots of bandwidth, one of the most important resources in the data warehouse. HDFS stores data in three different DataNodes by default. It is also worth mentioning that the location of three DataNodes. The first DataNodes and second one are located at the same rack, while the third DataNode is located at a different rack. This strategy is aimed to improving write performance and saving bandwidth without harming fault tolerance. Specifically, if one rack faces some problems, there are still other copies available. The two copies on the same rack could reduce the traffic between racks, because they only use ToR switch. Moreover, these policies also allow the NameNode distribute tasks to the nearest DataNode, which reduces the latency of computing. 

![[Pasted image 20221108175156.png]]

According to Brewerâ€™s CAP theorem, the I/O operation is usually the trickiest part in distributed systems, as those systems should always maintain partition tolerance. The result of the tread-off is that HDFS gives up a certain level of availability because the authors acknowledge that programmer cannot be certain of the time to process an operation. Conversely, we can see that did well in consistency and partition tolerance by lease and verifying data with NameNodes. From this point, HDFS can handle storage of immutable documents, like the cache of search engines, some released statistics files, etc. Those data are viewed frequently and will not be changed. Moreover, we can imagine that if DataNodes located in different countries, users could access to the data nearest to them, thus speeding up access and achieving load balance. HDFS supports MapReduce and Spark well. According to the principle of calculating could get close to data, computing nodes always use the closeset copy. Moreover, the result also be storaged in HDFS. HDFS not only could save bandwidth and accelerated calculation but also guaranteed security of results. 


