[Ray: A Distributed Framework for Emerging AI Applications](https://www.usenix.org/system/files/osdi18-moritz.pdf)

Nowadays, an intelligent system that can react to dynamic environments (reinforcement learning, or RL) is required for an increasing number of tasks.However, due to the features of RL and the varying outcomes with different data, the framework must allow for fine-grained calculations and support heterogeneity in time and resource utilization. Additionally, in order to manage millions of diverse jobs per second with millisecond latencies, dynamic computation is another important feature for the framework. Moreover, the solutions developed in recent years are either missing some features or are one-off systems that need to be developed separately for each application. To address this issue, the authors proposed an all-in-one system capable of handling a wide range of data and tasks in a single system.

Like the previous systems, Ray also provides a unified interface for the tasks. To solve the biggest challenge, dealing with dynamic workload and stateful computations, Ray proposed an interface that can handle task-parallel and actor-based assignments to deal with stateful and stateless computations. Another important change is that Ray splits the task scheduler and metadata store, which contains lineage information and objects, in order to provide an instant processing system with lineage-based fault tolerance. Those two components and the global control store (GCS) make up the system layer. The schedulers are local-schedule-first, and they could also forward to the global scheduler when resources are not enough. Meanwhile, GSC keeps the majority of the system stateless, improving fault tolerance and making the system more flexible. Also, the storage of data is implemented by shared memory, which enables different tasks to share data or results.

If we compare the existing frameworks with Ray, we can find that the features of those frameworks do not satisfy the requirements of RL. Moreover, those solutions that only involve stacking components together cannot address the latency issue. As a result, Ray integrates many existing simulators and deep learning frameworks while guaranteeing very low latency. [[MapReduce]], [[Spark]] and [[Dryad]] only support coarse-grained operations, while RL needs fine-grained data to simulate different environments. Additionally, those dataflow systems were also limited in the field of systems instead of platforms, which means they did not provide a control plane or a scheduler. TensorFlow and its platform, [[TensorFlow Extended]], do support distributed systems, however, they do not support simulation and serving, which play important roles in RL systems. Moreover, due to the feature of a static graph instead of a dynamic graph, the network structure of TensorFlow and MXNet cannot be changed while training. As a platform, flexible APIs are not the only requirement. Those APIs also need to be suitable for task requirements. However, only a small part of previous systems provided the API to take the first few results, which reduced fault tolerance.

If we say MapReduce offered a unified distributed computing system, and TensorFlow Extended provides a unified deep learning training interface, then we could say Ray not only provides a distributed and unified approach to RL training, but it also provides a unified management and storage system.