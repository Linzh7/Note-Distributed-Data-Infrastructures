[Real-time Data Infrastructure at Uber](https://dl.acm.org/doi/10.1145/3448016.3457552)

Uber is a company provides vary fields services, and some of the services need to make decision in seconds. Moreover, Uber also wants to explore stream data to difference roles with a huge volume of data. Therefore, Uber refined Apache ecosystem to satisfy their requirements.

The structure of data processing system in Uber is a modified version of Apache. This is a hierarchical system, which could be broadly divided into three layers: storage, streaming and computation, analyzation. Besides, there is a metadata component provides interface to manage  the metadata for all layers.

There are two data types should be stored in this system, living streaming data and archival data from the whole system. The latter use [[HDFS]] to guarantee the fault-tolerance, meanwhile, the former use Kafka to provide streaming storage. Because data in PB magnitude uploaded to Uber every day, the processing system must support large scale. Therefore, Uber proposed cluster federation and dead letter queue.(addmore? like features of kafka)

The scale and workloads impact not only on storage, but also on steaming and computation. Flink is a high-performance engine in industry, which has good back pressure handling ability comparing with Strom and less memory consuming than [[Spark]]. Though Flink is a great choice, there are still some shortcomings need to overcome. Therefore, Uber improved its basic query function. Moreover, Uber also implemented two different technologies for storage and batch processing.

For a company, analyzation is important. Therefore, Uber uses Apache Pinot, an online analytical processing system, for high-level query and analyze with low latency and TB-scale data support.  Uber also modifies Pinot a lot to meet the demand, specifically, fine-grained semantics and full SQL support. Moreover, Presto is also involved in this part to provide flexiable and extensible in-memory query.

Uber also made an all-in-one system which integrated a number of components. Generally, Uber uses components belong to Apache ecosystem. From this perspective, we can find that those components can easily embed into a system. For storage layer, they may not have another choice except [[HDFS]], a distributed storage system suiting for the Uber's distributed computing infrastructures. About the Streaming, Uber adds some new features to Kafka, such as pub-sub interfaces with at least once semantics. 

A computing layer having at least one semantic that can deal with both storage and streams It then employs an Online Analytical Processing Layer to provide high QPS and low-latency analytical queries . After that, there is a SQL layer that can function with both compute and OLAP and provides simplicity of use and query flexibility. The last two tiers are a programming layer for each user and a metadata layer for each of these layers.